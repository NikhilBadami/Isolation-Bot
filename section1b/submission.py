
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: notebook.ipynb

import time
from isolation import Board

# Credits if any
# 1) https://stackoverflow.com/questions/13145368/find-the-maximum-value-in-a-list-of-tuples-in-python # used as reference for python-max function
# 2)
# 3)

class OpenMoveEvalFn:
    def score(self, game, my_player=None):
        """Score the current game state
        Evaluation function that outputs a score equal to how many
        moves are open for AI player on the board minus how many moves
        are open for Opponent's player on the board.

        Note:
            If you think of better evaluation function, do it in CustomEvalFn below.

            Args
                game (Board): The board and game state.
                my_player (Player object): This specifies which player you are.

            Returns:
                float: The current state's score. MyMoves-OppMoves.

            """

        my_player_moves = game.get_player_moves(my_player)
        opp_moves = game.get_opponent_moves(my_player)
        number_of_moves = len(my_player_moves) - len(opp_moves)
        return number_of_moves


######################################################################
########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################
######## IF YOU WANT TO CALL OR TEST IT CREATE A NEW CELL ############
######################################################################
##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######
################ END OF LOCAL TEST CODE SECTION ######################

class CustomPlayer:
    # TODO: finish this class!
    """Player that chooses a move using your evaluation function
    and a minimax algorithm with alpha-beta pruning.
    You must finish and test this player to make sure it properly
    uses minimax and alpha-beta to return a good move."""

    def __init__(self, search_depth=4, eval_fn=OpenMoveEvalFn()):
        """Initializes your player.

        if you find yourself with a superior eval function, update the default
        value of `eval_fn` to `CustomEvalFn()`

        Args:
            search_depth (int): The depth to which your agent will search
            eval_fn (function): Evaluation function used by your agent
        """
        self.eval_fn = eval_fn
        self.search_depth = search_depth

    def move(self, game, time_left):
        """Called to determine one move by your agent

        Note:
            1. Do NOT change the name of this 'move' function. We are going to call
            this function directly.
            2. Call alphabeta instead of minimax once implemented.
        Args:
            game (Board): The board and game state.
            time_left (function): Used to determine time left before timeout

        Returns:
            tuple: (int,int): Your best move
        """
        best_move, utility = alphabeta(self, game, time_left, depth=self.search_depth)
        return best_move

    def utility(self, game, my_turn):
        """You can handle special cases here (e.g. endgame)"""
        return self.eval_fn.score(game, self)



###################################################################
########## DON'T WRITE ANY CODE OUTSIDE THE CLASS! ################
###### IF YOU WANT TO CALL OR TEST IT CREATE A NEW CELL ###########
###################################################################

from operator import itemgetter
from random import shuffle

def minimax(player, game, time_left, depth, my_turn=True):
    """Implementation of the minimax algorithm.
    Args:
        player (CustomPlayer): This is the instantiation of CustomPlayer()
            that represents your agent. It is used to call anything you
            need from the CustomPlayer class (the utility() method, for example,
            or any class variables that belong to CustomPlayer()).
        game (Board): A board and game state.
        time_left (function): Used to determine time left before timeout
        depth: Used to track how deep you are in the search tree
        my_turn (bool): True if you are computing scores during your turn.

    Returns:
        (tuple, int): best_move, val
    """

    def __minimax_helper__(player, projected_game, time_left, cur_depth, max_depth, my_turn):
        """
            Args:
                player: same as minimax()
                projected_game: game state if move in previous step was made
                time_left: same as minimax()
                cur_depth: current depth of search from root
                max_depth: maximum depth searchable
                my_turn: same as minimax()
            Returns:
                int: utility of this game state for AI i.e. utility of making this move if starting from root
        """
        node_utility = player.eval_fn.score(projected_game, player)

        # Stop evaluating and immediately return if less than 6.7ms remains
        TIMEOUT_THRESHOLD = 6.7

        # If at maximum search depth, treat this node as a termination leaf and calculate utility
        if cur_depth >= max_depth or time_left() < TIMEOUT_THRESHOLD:
            return node_utility

        possible_actions = None
        # Check AI moves or opponents moves depending on whose turn it is
        if my_turn:
            possible_actions = projected_game.get_player_moves(player)
        else:
            possible_actions = projected_game.get_opponent_moves(player)
        if len(possible_actions) == 0:
            # Assumption here is that the game is over
            return node_utility

        best_utility = None
        for action in possible_actions:
            if time_left() < TIMEOUT_THRESHOLD:
                if best_utility is None:
                    best_utility = node_utility
                break
            new_projected_game, is_over, winner = projected_game.forecast_move(action)
            if is_over:
                utility = player.eval_fn.score(new_projected_game, player)
                best_utility = __utility_helper__(my_turn, best_utility, utility)
            else:
                utility = __minimax_helper__(player, new_projected_game, time_left, cur_depth+1, max_depth, not my_turn)
                best_utility = __utility_helper__(my_turn, best_utility, utility)

        return best_utility

    def __utility_helper__(my_turn, best_utility, utility):
        """
            Args:
                my_turn: boolean indicating who's turn it is
                best_utility: best utility value found so far
                utility: The most recently returned utility value
            Returns:
                float: New best utility value
        """
        new_best_utility = None
        if best_utility is None:
            new_best_utility = utility
        elif my_turn:
            new_best_utility = max([best_utility, utility])
        else:
            new_best_utility = min([best_utility, utility])
        return new_best_utility

    possible_actions = game.get_player_moves(player)
    action_utility_list = []
    for action in possible_actions:
        new_projected_game, is_over, winner = game.forecast_move(action)
        if is_over:
            utility = player.eval_fn.score(new_projected_game, player)
            action_utility_list.append((action, utility))
        else:
            utility = __minimax_helper__(player, new_projected_game, time_left, 1, depth, not my_turn)
            action_utility_list.append((action, utility))

    # Find move with highest utility value
    best_move_utility_pair = max(action_utility_list, key=itemgetter(1))
    return best_move_utility_pair[0], best_move_utility_pair[1]

######################################################################
########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################
######## IF YOU WANT TO CALL OR TEST IT CREATE A NEW CELL ############
######################################################################
##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######
#tests.beatRandom(CustomPlayer)
#tests.minimaxTest(CustomPlayer, minimax)
################ END OF LOCAL TEST CODE SECTION ######################

class HeapNode:
    """
        Class that will be used as a node in the min/max heap for node ordering
    """

    def __init__(self, utility, move, node_heap=None):
        """
            Args:
                utility: utility value associatd with this move
                move: The move the agent could make
                node_heap: A min/max heap of all the moves possible from this node. Will be a max
                           heap for a max node and vice versa. Will not be populated beyond depth 3
        """
        self.utility = utility
        self.move = move
        self.node_heap = node_heap

    def __lt__(self, node=None):
        """
            Comparator for class. Used in min/max heap
            Args:
                node: Node being compared to
            Returns:
                boolean: whether or not the self node is smaller than the comparing node
        """
        if node is None:
            # None objects are treated as infinity
            return False
        return self.utility < node.utility

def alphabeta(player, game, time_left, depth, alpha=float("-inf"), beta=float("inf"), my_turn=True):
    """Implementation of the alphabeta algorithm.

    Args:
        player (CustomPlayer): This is the instantiation of CustomPlayer()
            that represents your agent. It is used to call anything you need
            from the CustomPlayer class (the utility() method, for example,
            or any class variables that belong to CustomPlayer())
        game (Board): A board and game state.
        time_left (function): Used to determine time left before timeout
        depth: Used to track how deep you are in the search tree
        alpha (float): Alpha value for pruning
        beta (float): Beta value for pruning
        my_turn (bool): True if you are computing scores during your turn.

    Returns:
        (tuple, int): best_move, val
    """

    def __alphabeta_helper__(player, projected_game, time_left, cur_depth, max_depth, alpha, beta, my_turn, heap):
        """
            Args:
                player: same as alphabeta()
                projected_game: game state if move in previous step was made
                time_left: same as alphabeta()
                cur_depth: current depth of search from root
                max_depth: maximum depth searchable
                heap (HeapNode): max/min heap specifying best moves
                my_turn: same as alphabeta()
                alpha: same as alphabeta()
                beta: same as alphabeta()
            Returns:
                int: utility of this game state for AI i.e. utility of making this move if starting from root
        """
        node_utility = player.eval_fn.score(projected_game, player)

        # Stop evaluating and immediately return if less than 6.7ms remains
        TIMEOUT_THRESHOLD = 7

        # Max depth for which to heapify children
        MAX_HEAP_DEPTH = 3

        # If at maximum search depth, treat this node as a termination leaf and calculate utility
        if cur_depth >= max_depth or time_left() < TIMEOUT_THRESHOLD:
            return node_utility, None

        possible_actions = None
        # Check AI moves or opponents moves depending on whose turn it is
        if my_turn:
            possible_actions = projected_game.get_player_moves(player)
        else:
            possible_actions = projected_game.get_opponent_moves(player)
        if len(possible_actions) == 0:
            # Assumption here is that the game is over
            return node_utility, None

        # Random order to take advantage of pruning
        # shuffle(possible_actions)

        best_utility = None
        new_heap = None
        action_utility_list = []

        idx = 0
        if heap is not None:
            for node in heap:
                if time_left() < TIMEOUT_THRESHOLD:
                    if best_utility is None:
                        best_utility = node_utility
                    break
                new_projected_game, _, __ = projected_game.forecast_move(node.move)
                utility, child_heap = __alphabeta_helper__(player, new_projected_game, time_left, cur_depth+1, max_depth, alpha, beta, not my_turn, node.node_heap)
                new_node = HeapNode(utility, node.move, child_heap)
                action_utility_list.append(new_node)
                best_utility = __utility_helper__(my_turn, best_utility, utility)
                idx += 1

                if (best_utility >= beta if my_turn else best_utility <= alpha):
                    break
                alpha, beta = __set_alphabeta__(my_turn, best_utility, alpha, beta)
        else:
            for action in possible_actions:
                if time_left() < TIMEOUT_THRESHOLD:
                    if best_utility is None:
                        best_utility = node_utility
                    break
                new_projected_game, _, __ = projected_game.forecast_move(action)
                utility, child_heap = __alphabeta_helper__(player, new_projected_game, time_left, cur_depth+1, max_depth, alpha, beta, not my_turn, None)
                new_node = HeapNode(utility, action, child_heap)
                action_utility_list.append(new_node)
                best_utility = __utility_helper__(my_turn, best_utility, utility)
                idx += 1

                if (best_utility >= beta if my_turn else best_utility <= alpha):
                    break
                alpha, beta = __set_alphabeta__(my_turn, best_utility, alpha, beta)

        # Check to see if action_utilities need to be heapified
        if cur_depth <= MAX_HEAP_DEPTH and time_left() >= TIMEOUT_THRESHOLD:
            if my_turn:
                # Is a max node
                action_utility_list.sort(reverse=True)
            else:
                # Is a min node
                action_utility_list.sort()
            new_heap = action_utility_list
            # Check to see if there are nodes that were pruned in case they need to be considered
            # in the next iteration
            if heap is not None:
                if idx < len(heap):
                    while idx < len(heap):
                        if time_left() < TIMEOUT_THRESHOLD:
                            break
                        existing_node = heap[idx]
                        new_node = HeapNode(existing_node.utility, existing_node.move)
                        new_heap.append(new_node)
                        idx += 1
            else:
                if idx < len(possible_actions):
                    while idx < len(possible_actions):
                        if time_left() < TIMEOUT_THRESHOLD:
                            break
                        new_node = HeapNode(0, possible_actions[idx])
                        new_heap.append(new_node)
                        idx += 1

        return best_utility, new_heap

    def __utility_helper__(my_turn, best_utility, utility):
        """
            Args:
                my_turn: boolean indicating who's turn it is
                best_utility: best utility value found so far
                utility: The most recently returned utility value
            Returns:
                float: New best utility value
        """
        new_best_utility = None
        if best_utility is None:
            new_best_utility = utility
        elif my_turn:
            new_best_utility = max([best_utility, utility])
        else:
            new_best_utility = min([best_utility, utility])
        return new_best_utility

    def __set_alphabeta__(my_turn, best_utility, alpha, beta):
        """
            Args:
                my_turn: boolean indicating who's turn it is
                best_utility: best utility value found so far
                alpha: same as alphabeta()
                beta: same as alphabeta()
            Returns:
                (float, float): New alpha or beta value
        """
        if my_turn:
            new_alpha = max([best_utility, alpha])
            return new_alpha, beta
        else:
            new_beta = min([best_utility, beta])
            return alpha, new_beta

    ################################################################################# Main function body
    MASTER_TIMEOUT_THRESHOLD = 7
    possible_actions = game.get_player_moves(player)
    best_move_utility_pair = None
    max_heap = None
    # Assumption is we'd never make it to depth 100,000 so we can treat it as infinity
    for max_depth in range(1, 100000):
        alpha = float("-inf")
        action_utility_list = []

        # Start basic alpha-beta search
        if max_heap is not None:
            for node in max_heap:
                new_projected_game, _, __ = game.forecast_move(node.move)
                utility, heap = __alphabeta_helper__(player, new_projected_game, time_left, 1, max_depth, alpha, beta, not my_turn, node.node_heap)
                new_node = HeapNode(utility, node.move, heap)
                action_utility_list.append(new_node)
                alpha = max([utility, alpha])
        else:
            for action in possible_actions:
                new_projected_game, _, __ = game.forecast_move(action)
                utility, heap = __alphabeta_helper__(player, new_projected_game, time_left, 1, max_depth, alpha, beta, not my_turn, None)
                new_node = HeapNode(utility, action, heap)
                action_utility_list.append(new_node)
                alpha = max([utility, alpha])
        # End basic alpha beta search

        if time_left() < MASTER_TIMEOUT_THRESHOLD:
            break

        # Create "max heap" out of action_utility_pair list
        action_utility_list.sort(reverse=True)
        max_heap = action_utility_list
        best_move = max_heap[0]
        best_move_utility_pair = (best_move.move, best_move.utility)

    return best_move_utility_pair[0], best_move_utility_pair[1]

######################################################################
########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################
######## IF YOU WANT TO CALL OR TEST IT CREATE A NEW CELL ############
######################################################################
##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######
#tests.minimaxTest(CustomPlayer, minimax)
#tests.beatRandom(CustomPlayer)
#tests.agentvsagent(CustomPlayerTest, CustomPlayer)
################ END OF LOCAL TEST CODE SECTION ######################

class CustomEvalFn:
    def __init__(self):
        pass

    def score(self, game, my_player=None):
        """Score the current game state.

        Custom evaluation function that acts however you think it should. This
        is not required but highly encouraged if you want to build the best
        AI possible.

        Args:
            game (Board): The board and game state.
            my_player (Player object): This specifies which player you are.

        Returns:
            float: The current state's score, based on your own heuristic.
        """

        # TODO: finish this function!
        raise NotImplementedError

######################################################################
############ DON'T WRITE ANY CODE OUTSIDE THE CLASS! #################
######## IF YOU WANT TO CALL OR TEST IT CREATE A NEW CELL ############
######################################################################